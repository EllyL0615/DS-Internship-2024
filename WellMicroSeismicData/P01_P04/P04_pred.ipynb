{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT run this every time!\n",
    "df_og = pd.read_table('P04.awm', sep='\\s+', engine='python')\n",
    "df_og.to_pickle('P04.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = pd.read_pickle('P04.pkl')\n",
    "df_og    # WMSD after KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og[['Radius', 'ANT', 'GXYX', 'CURVE', 'WellMicroSeismicData']]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axes[0].scatter(df['Radius'], df['WellMicroSeismicData'], alpha=0.01)\n",
    "axes[1].scatter(df['ANT'], df['WellMicroSeismicData'], alpha=0.01)\n",
    "axes[2].scatter(df['GXYX'], df['WellMicroSeismicData'], alpha=0.01)\n",
    "axes[3].scatter(df['CURVE'], df['WellMicroSeismicData'], alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT run this every time!\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)    # 27264; 6816\n",
    "train_set.to_pickle('train_set.pkl')\n",
    "test_set.to_pickle('test_set.pkl')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle('train_set.pkl')\n",
    "test_set = pd.read_pickle('test_set.pkl')\n",
    "\n",
    "X = df[['Radius', 'ANT', 'GXYX', 'CURVE']].copy()\n",
    "y = df['WellMicroSeismicData'].copy()\n",
    "X_train = train_set[['Radius', 'ANT', 'GXYX', 'CURVE']].copy()    # X_train: feature vairables in training dataset\n",
    "y_train = train_set['WellMicroSeismicData'].copy()    # y_train : response variable in training dataset\n",
    "X_test = test_set[['Radius', 'ANT', 'GXYX', 'CURVE']].copy()    # X_test: feature vairables in testing dataset\n",
    "y_test = test_set['WellMicroSeismicData'].copy()    # y_test : response variable in testing dataset\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = StandardScaler().fit_transform(X)\n",
    "X_train_s = StandardScaler().fit_transform(X_train)\n",
    "X_test_s = StandardScaler().fit_transform(X_test)\n",
    "X_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions Using SciKit-Learn\n",
    "\n",
    "Models:\n",
    "- Linear\n",
    "- Polynomial\n",
    "- Decision Tree, Decision Tree with Bagging, Decision Tree with Adaptive Boosting, Random Forest\n",
    "- Extra Trees, Extra Trees with Bagging, Extra Trees with Adaptive Boosting\n",
    "- Gradient Boosting\n",
    "\n",
    "Metrics:\n",
    "- MSE\n",
    "- R2\n",
    "- Observed-Predict Plot\n",
    "\n",
    "\n",
    "**Final Decision**: \n",
    "1. Extra Trees with Bagging\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_s, y_train)\n",
    "\n",
    "lin_pred = lin_reg.predict(X_train_s)\n",
    "lin_mse = mean_squared_error(y_train, lin_pred)\n",
    "lin_r2 = r2_score(y_train, lin_pred)\n",
    "\n",
    "lin_pred_test = lin_reg.predict(X_test_s)\n",
    "lin_mse_test = mean_squared_error(y_test, lin_pred_test)\n",
    "lin_r2_test = r2_score(y_test, lin_pred_test)\n",
    "\n",
    "\n",
    "print(lin_mse, lin_r2, lin_mse_test, lin_r2_test)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, lin_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, lin_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=4)\n",
    "X_train_poly = poly_features.fit_transform(X_train_s)\n",
    "X_test_poly = poly_features.fit_transform(X_test_s)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "poly_pred = poly_reg.predict(X_train_poly)\n",
    "poly_mse = mean_squared_error(y_train, poly_pred)\n",
    "poly_r2 = r2_score(y_train, poly_pred)\n",
    "\n",
    "poly_pred_test = poly_reg.predict(X_test_poly)\n",
    "poly_mse_test = mean_squared_error(y_test, poly_pred_test)\n",
    "poly_r2_test = r2_score(y_test, poly_pred_test)\n",
    "\n",
    "\n",
    "print(poly_mse, poly_r2, poly_mse_test, poly_r2_test)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, poly_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, poly_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train_s, y_train)\n",
    "\n",
    "tree_pred = tree_reg.predict(X_train_s)\n",
    "tree_mse = mean_squared_error(y_train, tree_pred)\n",
    "tree_r2 = r2_score(y_train, tree_pred)\n",
    "\n",
    "tree_pred_test = tree_reg.predict(X_test_s)\n",
    "tree_mse_test = mean_squared_error(y_test, tree_pred_test)\n",
    "tree_r2_test = r2_score(y_test, tree_pred_test)\n",
    "\n",
    "\n",
    "print(tree_mse, tree_r2, tree_mse_test, tree_r2_test, tree_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, tree_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, tree_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "treebag_reg = BaggingRegressor(DecisionTreeRegressor(), bootstrap=True)\n",
    "treebag_reg.fit(X_train_s, y_train)\n",
    "\n",
    "treebag_pred = treebag_reg.predict(X_train_s)\n",
    "treebag_mse = mean_squared_error(y_train, treebag_pred)\n",
    "treebag_r2 = r2_score(y_train, treebag_pred)\n",
    "\n",
    "treebag_pred_test = treebag_reg.predict(X_test_s)\n",
    "treebag_mse_test = mean_squared_error(y_test, treebag_pred_test)\n",
    "treebag_r2_test = r2_score(y_test, treebag_pred_test)\n",
    "\n",
    "\n",
    "print(treebag_mse, treebag_r2, treebag_mse_test, treebag_r2_test)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, treebag_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, treebag_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "treeada_reg = AdaBoostRegressor(DecisionTreeRegressor())\n",
    "treeada_reg.fit(X_train_s, y_train)\n",
    "\n",
    "treeada_pred = treeada_reg.predict(X_train_s)\n",
    "treeada_mse = mean_squared_error(y_train, treeada_pred)\n",
    "treeada_r2 = r2_score(y_train, treeada_pred)\n",
    "\n",
    "treeada_pred_test = treeada_reg.predict(X_test_s)\n",
    "treeada_mse_test = mean_squared_error(y_test, treeada_pred_test)\n",
    "treeada_r2_test = r2_score(y_test, treeada_pred_test)\n",
    "\n",
    "\n",
    "print(treeada_mse, treeada_r2, treeada_mse_test, treeada_r2_test, treeada_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, treeada_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, treeada_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train_s, y_train)\n",
    "\n",
    "rf_pred = rf_reg.predict(X_train_s)\n",
    "rf_mse = mean_squared_error(y_train, rf_pred)\n",
    "rf_r2 = r2_score(y_train, rf_pred)\n",
    "\n",
    "rf_pred_test = rf_reg.predict(X_test_s)\n",
    "rf_mse_test = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_r2_test = r2_score(y_test, rf_pred_test)\n",
    "\n",
    "\n",
    "print(rf_mse, rf_r2, rf_mse_test, rf_r2_test, rf_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, rf_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, rf_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "et_reg = ExtraTreesRegressor()\n",
    "et_reg.fit(X_train_s, y_train)\n",
    "\n",
    "et_pred = et_reg.predict(X_train_s)\n",
    "et_mse = mean_squared_error(y_train, et_pred)\n",
    "et_r2 = r2_score(y_train, et_pred)\n",
    "\n",
    "et_pred_test = et_reg.predict(X_test_s)\n",
    "et_mse_test = mean_squared_error(y_test, et_pred_test)\n",
    "et_r2_test = r2_score(y_test, et_pred_test)\n",
    "\n",
    "\n",
    "print(et_mse, et_r2, et_mse_test, et_r2_test, et_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, et_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, et_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "etbag_reg = BaggingRegressor(ExtraTreesRegressor())\n",
    "etbag_reg.fit(X_train_s, y_train)\n",
    "\n",
    "etbag_pred = etbag_reg.predict(X_train_s)\n",
    "etbag_mse = mean_squared_error(y_train, etbag_pred)\n",
    "etbag_r2 = r2_score(y_train, etbag_pred)\n",
    "\n",
    "etbag_pred_test = etbag_reg.predict(X_test_s)\n",
    "etbag_mse_test = mean_squared_error(y_test, etbag_pred_test)\n",
    "etbag_r2_test = r2_score(y_test, etbag_pred_test)\n",
    "\n",
    "\n",
    "print(etbag_mse, etbag_r2, etbag_mse_test, etbag_r2_test)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, etbag_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, etbag_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "etada_reg = AdaBoostRegressor(ExtraTreesRegressor())\n",
    "etada_reg.fit(X_train_s, y_train)\n",
    "\n",
    "etada_pred = etada_reg.predict(X_train_s)\n",
    "etada_mse = mean_squared_error(y_train, etada_pred)\n",
    "etada_r2 = r2_score(y_train, etada_pred)\n",
    "\n",
    "etada_pred_test = etada_reg.predict(X_test_s)\n",
    "etada_mse_test = mean_squared_error(y_test, etada_pred_test)\n",
    "etada_r2_test = r2_score(y_test, etada_pred_test)\n",
    "\n",
    "\n",
    "print(etada_mse, etada_r2, etada_mse_test, etada_r2_test, etada_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, etada_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, etada_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(warm_start=True, subsample=0.25)\n",
    "gb_reg.fit(X_train_s, y_train)\n",
    "\n",
    "gb_pred = gb_reg.predict(X_train_s)\n",
    "nn_mse = mean_squared_error(y_train, gb_pred)\n",
    "gb_r2 = r2_score(y_train, gb_pred)\n",
    "\n",
    "gb_pred_test = gb_reg.predict(X_test_s)\n",
    "gb_mse_test = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_r2_test = r2_score(y_test, gb_pred_test)\n",
    "\n",
    "\n",
    "print(nn_mse, gb_r2, gb_mse_test, gb_r2_test, gb_reg.feature_importances_)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, gb_pred, alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, gb_pred_test, alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA using SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_s)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "pca.explained_variance_ratio_, pca.components_\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "# 1st\n",
    "axes[0,0].scatter(X_train_pca[:,0], X_train_pca[:,1], c=y_train, alpha=0.05)\n",
    "\n",
    "axes[0,1].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),1], alpha=0.05)\n",
    "\n",
    "axes[0,2].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),1], alpha=0.05)\n",
    "axes[0,2].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),0], X_train_pca[(y_train>0.1) & (y_train<0.2),1], alpha=0.05)\n",
    "\n",
    "axes[0,3].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),1], alpha=0.05)\n",
    "axes[0,3].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),0], X_train_pca[(y_train>0.1) & (y_train<0.2),1], alpha=0.05)\n",
    "axes[0,3].scatter(X_train_pca[(y_train>0.2) & (y_train<0.4),0], X_train_pca[(y_train>0.2) & (y_train<0.4),1], alpha=0.05)\n",
    "\n",
    "# 2nd\n",
    "axes[1,0].scatter(X_train_pca[:,0], X_train_pca[:,2], c=y_train, alpha=0.05)\n",
    "\n",
    "axes[1,1].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "\n",
    "axes[1,2].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "axes[1,2].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),0], X_train_pca[(y_train>0.1) & (y_train<0.2),2], alpha=0.05)\n",
    "\n",
    "axes[1,3].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),0], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "axes[1,3].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),0], X_train_pca[(y_train>0.1) & (y_train<0.2),2], alpha=0.05)\n",
    "axes[1,3].scatter(X_train_pca[(y_train>0.2) & (y_train<0.4),0], X_train_pca[(y_train>0.2) & (y_train<0.4),2], alpha=0.05)\n",
    "\n",
    "#3rd\n",
    "axes[2,0].scatter(X_train_pca[:,1], X_train_pca[:,2], c=y_train, alpha=0.05)\n",
    "\n",
    "axes[2,1].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),1], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "\n",
    "axes[2,2].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),1], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "axes[2,2].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),1], X_train_pca[(y_train>0.1) & (y_train<0.2),2], alpha=0.05)\n",
    "\n",
    "axes[2,3].scatter(X_train_pca[(y_train>0.0) & (y_train<0.1),1], X_train_pca[(y_train>0.0) & (y_train<0.1),2], alpha=0.05)\n",
    "axes[2,3].scatter(X_train_pca[(y_train>0.1) & (y_train<0.2),1], X_train_pca[(y_train>0.1) & (y_train<0.2),2], alpha=0.05)\n",
    "axes[2,3].scatter(X_train_pca[(y_train>0.2) & (y_train<0.4),1], X_train_pca[(y_train>0.2) & (y_train<0.4),2], alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.scatter(X_train_pca[(y_train>0.0) & (y_train<0.1), 0], X_train_pca[(y_train>0.0) & (y_train<0.1), 1], X_train_pca[(y_train>0.0) & (y_train<0.1), 2], alpha = 0.01)\n",
    "ax.scatter(X_train_pca[(y_train>0.1) & (y_train<0.2), 0], X_train_pca[(y_train>0.1) & (y_train<0.2), 1], X_train_pca[(y_train>0.1) & (y_train<0.2), 2], alpha = 0.01)\n",
    "ax.scatter(X_train_pca[(y_train>0.2) & (y_train<0.4), 0], X_train_pca[(y_train>0.2) & (y_train<0.4), 1], X_train_pca[(y_train>0.2) & (y_train<0.4), 2], alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Regression Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train_s, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
    "train_t = TensorDataset(X_train_t, y_train_t)\n",
    "trainloader = DataLoader(train_t, shuffle=True)\n",
    "\n",
    "X_test_t = torch.tensor(X_test_s, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(np.array(y_test), dtype=torch.float32)\n",
    "test_t = TensorDataset(X_test_t, y_test_t)\n",
    "testloader = DataLoader(test_t, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        f1 = F.relu(self.fc1(x))\n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        f3 = F.relu(self.fc3(f2))\n",
    "        output = self.fc4(f3).reshape(-1)\n",
    "        return output\n",
    "    \n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10000 == 9999:    # print every ...\n",
    "            print(f'[{epoch + 1},{i + 1:5d}] loss: {running_loss / 2000:.6f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    nn_pred = net(X_train_t)\n",
    "    nn_pred_test = net(X_test_t)\n",
    "    test_loss = criterion(nn_pred_test, y_test_t)\n",
    "\n",
    "nn_mse = mean_squared_error(y_train, nn_pred)\n",
    "nn_r2 = r2_score(y_train, nn_pred)\n",
    "\n",
    "nn_mse_test = mean_squared_error(y_test, nn_pred_test)\n",
    "nn_r2_test = r2_score(y_test, nn_pred_test)\n",
    "\n",
    "print(nn_mse, nn_mse_test, nn_r2, nn_r2_test)\n",
    "print(f'Test Loss: {test_loss.item(): .4f}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].scatter(y_train, nn_pred.detach().numpy(), alpha = 0.02)\n",
    "axes[0].plot((0, 0.4), (0, 0.4))\n",
    "axes[1].scatter(y_test, nn_pred_test.detach().numpy(), alpha = 0.05)\n",
    "axes[1].plot((0, 0.4), (0, 0.4))\n",
    "\n",
    "\n",
    "# 100e: 0.011220 0.0022 0.6686302542089703 0.6467765149613168\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '100e.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LatestPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
